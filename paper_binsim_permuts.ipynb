{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Simplification in Metabolomics\n",
    "\n",
    "Notebook to support the study on the application of **Bin**ary **Sim**plification as a competing form of pre-processing procedure for high-resolution metabolomics data.\n",
    "\n",
    "This is notebook `paper_binsim_permuts.ipynb`.\n",
    "\n",
    "\n",
    "## Organization of the Notebook\n",
    "\n",
    "- Set up database of data sets\n",
    "- Application of different pre-treatments (including BinSim) to each data set\n",
    "- **Permutation tests generation and figure representation**\n",
    "\n",
    "Permutation tests are slow to generate.\n",
    "\n",
    "**Warning**: Permutation tests will write a json file into a folder called **permuts** (if it doesn't exist, it will cause an error). Permutation test will happen if Generate = True in the cell before application of each one. Thus, a folder named **permuts** has to exist to run the notebook. Since the models built depend on the folds created for cross-validation analysis, if the notebook is ran, the results may vary slightly from the exact results presented in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Needed Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "# json for persistence\n",
    "import json\n",
    "from time import perf_counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "import scipy.spatial.distance as dist\n",
    "import scipy.cluster.hierarchy as hier\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import ticker\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Metabolinks package\n",
    "import metabolinks as mtl\n",
    "import metabolinks.transformations as transf\n",
    "\n",
    "# Python files in the repository\n",
    "import multianalysis as ma\n",
    "from elips import plot_confidence_ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of dataset records\n",
    "\n",
    "`datasets` is the global dict that holds all data sets. It is a **dict of dict's**.\n",
    "\n",
    "Each data set is **represented as a dict**.\n",
    "\n",
    "Each record has the following fields (keys):\n",
    "\n",
    "- `name`: the table/figure name of the data set\n",
    "- `source`: the biological source for each dataset\n",
    "- `mode`: the aquisition mode\n",
    "- `alignment`: the alignment used to generate the data matrix\n",
    "- `data`: the data matrix\n",
    "- `target`: the sample labels, possibly already integer encoded\n",
    "- `<treatment name>`: transformed data matrix. These treatment names can be\n",
    "    - `original`: an alias to `data`\n",
    "    - `Ionly`: missing value imputed data, only\n",
    "    - `P`: Pareto scaled data\n",
    "    - `NP`: Pareto scaled and normalized\n",
    "    - `NGP`: normalized, glog transformed and Pareto scaled\n",
    "    - `BinSim`: binary simplified data\n",
    "\n",
    "The keys of `datasets` may be shared with dicts holding records resulting from comparison analysis.\n",
    "\n",
    "Here are the keys (and respective names) of datasets used in this study:\n",
    "\n",
    "- GD_neg_global2 (GDg2-)\n",
    "- GD_pos_global2 (GDg2+)\n",
    "- GD_neg_class2 (GDc2-)\n",
    "- GD_pos_class2 (GDc2+)\n",
    "- YD (YD 2/15)\n",
    "- YD2 (YD 6/15)\n",
    "- vitis_types (GD types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of grapevine data sets\n",
    "\n",
    "Grapevine Datasets (Negative and Positive) - 33 samples belonging to 11 different grapevine varieties (3 samples per variety/biological group) of FT-ICR-MS metabolomics data obtained in negative and positive ionization mode.\n",
    "\n",
    "5 different _Vitis_ species (other than _V. vinifera_) varieties:\n",
    "\n",
    "- CAN - 3 Samples (14, 15, 16) of _V. candicans Engelmann_ (VIVC variety number: 13508)\n",
    "- RIP - 3 Samples (17, 18, 19) of _V. riparia Michaux_ (Riparia Gloire de Montpellier, VIVC variety number: 4824) \n",
    "- ROT - 3 Samples (20, 21, 22) of _V. rotundifolia_ (Muscadinia Rotundifolia Michaux cv. Rotundifolia, VIVC variety number: 13586)\n",
    "- RU - 3 Samples (35, 36, 37) of _V. rupestris Scheele_ (Rupestris du lot, VIVC variety number: 10389)\n",
    "- LAB - 3 Samples (8, 9, 10) of _V. labrusca_ (Isabella, VIVC variety number: 5560)\n",
    "\n",
    "6 different _V. vinifera_ cultivars varieties are:\n",
    "\n",
    "- SYL - 3 samples (11, 12, 13) of the subspecies _sylvestris_ (VIVC variety number: -)\n",
    "- CS - 3 Samples (29, 30, 31) of the subspecies _sativa_ cultivar Cabernet Sauvignon (VIVC variety number: 1929)\n",
    "- PN - 3 Samples (23, 24, 25) of the subspecies _sativa_ cultivar Pinot Noir (VIVC variety number: 9279)\n",
    "- REG - 3 Samples (38, 39, 40) of the subspecies _sativa_ cultivar Regent (VIVC variety number: 4572)\n",
    "- RL - 3 Samples (26, 27, 28) of the subspecies _sativa_ cultivar Riesling Weiss (VIVC variety number: 10077)\n",
    "- TRI - 3 Samples (32, 33, 34) of the subspecies _sativa_ cultivar Cabernet Sauvignon (VIVC variety number: 15685)\n",
    "\n",
    "Data acquired by Maia et al. (2020):\n",
    "\n",
    "- Maia M, Ferreira AEN, Nascimento R, et al. Integrating metabolomics and targeted gene expression to uncover potential biomarkers of fungal / oomycetes ‑ associated disease susceptibility in grapevine. Sci Rep. Published online 2020:1-15. doi:10.1038/s41598-020-72781-2\n",
    "- Maia M, Figueiredo A, Silva MS, Ferreira A. Grapevine untargeted metabolomics to uncover potential biomarkers of fungal/oomycetes-associated diseases. 2020. doi:10.6084/m9.figshare.12357314.v1\n",
    "\n",
    "**Peak Alignment** and **Peak Filtering** were performed with function `metabolinks.peak_alignment.align()`. Human leucine enkephalin (Sigma Aldrich) was used as the reference feature (internal standard, [M+H]+ = 556.276575 Da or [M-H]- = 554.262022 Da).\n",
    "\n",
    "**4** data matrices were constructed from this data:\n",
    "\n",
    "- Data sets named `GD_pos_global2` (GDg2+) and `GD_neg_global2` (GDg2-) were generated after retaining only features that occur (globally) at least twice in all 33 samples of the data sets (filtering/alignment) for the **positive mode** data acquisition and the **negative mode** data acquisition, respectively.\n",
    "- Data sets named `GD_pos_class2` (GDc2+) and `GD_neg_class2` (GDc2-) were generated after retaining only features that occur at least twice in the three replicates of at least one _Vitis_ variety in the data sets (filtering/alignment) for the **positive mode** data acquisition and the **negative mode** data acquisition, respectively.\n",
    "\n",
    "For the purpose of assessing the performance of supervised methods each of these four datasets was used with target labels defining classes corresponding to replicates of each of the 11 Vitis species/cultivars.\n",
    "\n",
    "For the purpose of assessing the performance of supervised methods under a binary (two-class) problem, data set `GD_neg_class2` was also used with target labels defining two classes: Vitis vinifera cultivars and \"wild\", non-vinifera Vitis species. This is dataset `vitis_types` (GD types)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the yeast data set\n",
    "\n",
    "Yeast dataset - 15 samples belonging to 5 different yeast strains of _Saccharomyces cerevisiae_ (3 biological replicates per strain/biological group) of FT-ICR-MS metabolomics data obtained in positive ionization mode. The 5 strains were: the reference strain BY4741 (represented as BY) and 4 single-gene deletion mutants of this strain – ΔGLO1 (GLO1), ΔGLO2 (GLO2), ΔGRE3 (GRE3) and ΔENO1 (ENO1). These deleted genes are directly or indirectly related to methylglyoxal metabolism.\n",
    "\n",
    "Data acquired by Luz et al. (2021):\n",
    "\n",
    "- Luz J, Pendão AS, Silva MS, Cordeiro C. FT-ICR-MS based untargeted metabolomics for the discrimination of yeast mutants. 2021. doi:10.6084/m9.figshare.15173559.v1\n",
    "\n",
    "**Peak Alignment** and **Peak Filtering** was performed with MetaboScape 4.0 software (see reference above for details in sample preparation, pre-processing, formula assignment). In short, Yeast Dataset was obtained with Electrospray Ionization in Positive Mode and pre-processed by MetaboScape 4.0 (Bruker Daltonics). Human leucine enkephalin (Sigma Aldrich) was used as the reference feature (internal standard, [M+H]+ = 556.276575 Da or [M-H]- = 554.262022 Da).\n",
    "\n",
    "**2** data matrices were constructed from this data:\n",
    "\n",
    "- Data set named `YD` (YD 2/15) was generated after retaining only features that occur (globally) at least twice in all 15 samples (filtering/alignment).\n",
    "- Data set named `YD2` (YD 6/15) was generated after retaining only features that occur (globally) at least six times in all 15 samples (filtering/alignment).\n",
    "\n",
    "For the purpose of assessing the performance of supervised methods, this data set was used with target labels defining classes corresponding to replicates of each of the 4 yeast strains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd() / \"paperimages\" / 'processed_data.json'\n",
    "storepath = Path.cwd() / \"paperimages\" / 'processed_data.h5'\n",
    "with pd.HDFStore(storepath) as store:\n",
    "\n",
    "    with open(path, encoding='utf8') as read_file:\n",
    "        datasets = json.load(read_file)\n",
    "    \n",
    "    for dskey, dataset in datasets.items():\n",
    "        for key in dataset:\n",
    "            value = dataset[key]\n",
    "            if isinstance(value, str) and value.startswith(\"INSTORE\"):\n",
    "                storekey = value.split(\"_\", 1)[1]\n",
    "                dataset[key] = store[storekey]\n",
    "            # convert colors to tuples, since they are read as lists from json file\n",
    "            elif key == 'label_colors':\n",
    "                dataset[key] = {lbl: tuple(c) for lbl, c in value.items()}\n",
    "            elif key == 'sample_colors':\n",
    "                dataset[key] = [tuple(c) for c in value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Supervised Statistical Analysis - Permutation Tests\n",
    "\n",
    "The Supervised Statistical Analysis methods used will be Random Forest and PLS-DA.\n",
    "\n",
    "The performance of the classifiers will be evaluated by their predictive **accuracy** (which will always be estimated by internal stratified 3-fold cross-validation or 5-fold cross-validation in `vitis_types`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Tests (Very Slow)\n",
    "\n",
    "Permutation tests is based on shuffling the labels of the different samples, shuflling the groups where they belong with the intent to see if the classifier tested, whether it is Random Forest or PLS-DA found a significant class structure in the data - assess the significance of the predictive accuracy results. \n",
    "\n",
    "For that a random k-fold cross-validation is performed on the original dataset (to serve as a comparation point) and on 500 permutations of datasets with labels randomly shuffled around. The models are evaluated by their predictive accuracies. \n",
    "\n",
    "The empirical p-value is given by (the number of times the permutation accuracy was bigger than the random k-fold cross-validation made with the original dataset + 1) / (number of permutations + 1) (source: Ojala and Garriga, 2010).\n",
    "\n",
    "Ojala M, Garriga GC. Permutation Tests for Studying Classifier Performance. In: 2009 Ninth IEEE International Conference on Data Mining. ; 2009:908-913. doi:10.1109/ICDM.2009.108\n",
    "\n",
    "Histograms with the prediction accuracy of the different permutations were plotted and compared to the accuracy got with the original dataset.\n",
    "\n",
    "### Permutation Tests - Random Forests\n",
    "\n",
    "Use of `permutation_RF` function from multianalysis.py. See details about the application of this function in the multianalysis.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json for persistence\n",
    "import json\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `GENERATE = True` to perform permutation tests and persist results in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = True #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    iter_num=500 # number of permutations\n",
    "\n",
    "\n",
    "    permuts_RF = []\n",
    "\n",
    "    to_permute = [name for name in datasets]# if 'global2' in name]\n",
    "    for name in to_permute:\n",
    "        for treatment in ('P', 'P_RF', 'NP', 'NP_RF', 'NGP', 'NGP_RF', 'BinSim'):\n",
    "            dataset = datasets[name]\n",
    "            print(f'{iter_num} permutations (Random Forest) for {name} with treatment {treatment}', end=' ...')\n",
    "            n_fold = 5 if name == 'vitis_types' else 3\n",
    "            start = perf_counter()\n",
    "            permutations = ma.permutation_RF(dataset[treatment], dataset['target'], iter_num=iter_num, n_fold=n_fold, n_trees=100)\n",
    "            res = {'dataset': name, 'treatment': treatment,\n",
    "                   'non_permuted_CV': permutations[0],\n",
    "                   'permutations': permutations[1],\n",
    "                   'p-value': permutations[2]}       \n",
    "            permuts_RF.append(res)\n",
    "            end = perf_counter()\n",
    "            pvalue = permutations[2]\n",
    "            print(f'Done! took {(end - start):.3f} s, p-value = {pvalue}')\n",
    "    \n",
    "    # Store in json file\n",
    "    fname = 'paperimages/permuts_rf.json'\n",
    "    with open(fname, \"w\", encoding='utf8') as write_file:\n",
    "        json.dump(permuts_RF, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Tests - PLS-DA\n",
    "\n",
    "Use of `permutation_PLSDA` function from multianalysis.py. See details about the application of this function in the multianalysis.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "if GENERATE:\n",
    "    iter_num=500\n",
    "\n",
    "    permuts_PLSDA = []\n",
    "\n",
    "    to_permute = [name for name in datasets] # if 'global2' in name]\n",
    "    for name in to_permute:\n",
    "        for treatment in ('P', 'P_RF', 'NP', 'NP_RF', 'NGP', 'NGP_RF', 'BinSim'):\n",
    "            dataset = datasets[name]\n",
    "            print(f'Permutation test (PLS-DA) for {name} with treatment {treatment}', end=' ...')\n",
    "            n_comp = 11 if name.startswith('GD') else 6\n",
    "            n_fold = 5 if name == 'vitis_types' else 3\n",
    "            start = perf_counter()\n",
    "            permutations = ma.permutation_PLSDA(dataset[treatment], dataset['target'], n_comp=11,\n",
    "                                                iter_num=iter_num, n_fold=n_fold)\n",
    "            res = {'dataset': name, 'treatment': treatment,\n",
    "                   'non_permuted_CV': permutations[0],\n",
    "                   'permutations': permutations[1],\n",
    "                   'p-value': permutations[2]}\n",
    "            permuts_PLSDA.append(res)\n",
    "            end = perf_counter()\n",
    "            pvalue = permutations[2]\n",
    "            print(f'Done! took {(end - start):.3f} s, p-value = {pvalue:10.5f}')\n",
    "            \n",
    "    # Store in json file\n",
    "    fname = 'paperimages/permuts_plsda.json'\n",
    "    with open(fname, \"w\", encoding='utf8') as write_file:\n",
    "        json.dump(permuts_PLSDA, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from json file - random forests\n",
    "fname = 'paperimages/permuts_rf.json'\n",
    "with open(fname, \"r\", encoding='utf8') as read_file:\n",
    "    permuts_RF = json.load(read_file)\n",
    "\n",
    "for p in permuts_RF:\n",
    "    print(f\"{p['dataset']:<20}{p['treatment']:<8}{p['p-value']:10.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from json file - PLS-DA\n",
    "fname = 'paperimages/permuts_plsda.json'\n",
    "with open(fname, \"r\", encoding='utf8') as read_file:\n",
    "    permuts_PLSDA = json.load(read_file)\n",
    "\n",
    "for p in permuts_PLSDA:\n",
    "    print(f\"{p['dataset']:<20}{p['treatment']:<8}{p['p-value']:10.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Permutations test results - Histograms\n",
    "\n",
    "Nº Occurences (of the permutations) vs CV prediction acuracy - The distribution of average prediction accuracy of 500 permutations\n",
    "\n",
    "1st Figure - Random Forest\n",
    "\n",
    "2nd Figure - PLS-DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, axes = plt.subplots(7, 4, figsize = (10,16), sharey='row', sharex='col')\n",
    "        colors = sns.color_palette('tab10', 4)\n",
    "        ylim = [0,200]\n",
    "        treatments = ['P','NP','NGP','BinSim']\n",
    "        \n",
    "        for row, dskey in enumerate(datasets):\n",
    "\n",
    "            to_plot = [p for p in permuts_RF if p['dataset'] == dskey]\n",
    "\n",
    "            n_labels = len(datasets[dskey]['target'])\n",
    "            n_bins = 34 if dskey == 'vitis_types' else 16\n",
    "\n",
    "            for ax, p, tname, color in zip(axes[row].ravel(), to_plot, treatments, colors):\n",
    "                ax.hist(np.array(p['permutations'])*100, range=(0, 100.01), label=name + ' Permutations',\n",
    "                        bins=n_bins, edgecolor='black', color=color)\n",
    "                #ax.axvline(p['non_permuted_CV']*100)\n",
    "\n",
    "                ax.plot(2 * [p['non_permuted_CV'] * 100], ylim, '-', linewidth=3, color=color, #alpha = 0.5,\n",
    "                         label=name + ' (pvalue %.5f)' % p['p-value'], solid_capstyle='round')\n",
    "                #q.set(xlabel='Cross Validation Prediction Accuracy (%)', ylabel='Nº of occurrences', fontsize=12)\n",
    "                #ax.set_xlabel('CV Prediction Accuracy (%)')\n",
    "                #ax.set_ylabel('Nº of occurrences')\n",
    "                props = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "                ax.text(90, 190, 'p-value = %.3f' % p['p-value'], bbox=props, ha='right', fontsize='small')\n",
    "                ax.set_title(f\"{datasets[dskey]['name']}, {tname}\", color=color)\n",
    "                ax.set_ylim(0,250)\n",
    "\n",
    "        f.text(0.5, 0.01, 'CV Prediction Accuracy (%)', ha='center', va='top')\n",
    "        #f.text(0, 0.5, 'Counts', ha='center', va='top',rotation=90)\n",
    "        \n",
    "        \n",
    "        f.suptitle(f'Permutation tests for Random Forests')\n",
    "        plt.tight_layout()\n",
    "        f.savefig('paperimages/permutations_RF.pdf', dpi=200)\n",
    "        f.savefig('paperimages/permutations_RF.png', dpi=600)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"):\n",
    "    with sns.plotting_context(\"notebook\", font_scale=1.2):\n",
    "        f, axes = plt.subplots(7, 4, figsize = (10,16), sharey='row', sharex='col')\n",
    "        colors = sns.color_palette('tab10', 4)\n",
    "        ylim = [0,200]\n",
    "        treatments = ['P','NP','NGP','BinSim']\n",
    "        \n",
    "        for row, dskey in enumerate(datasets):\n",
    "\n",
    "            to_plot = [p for p in permuts_PLSDA if p['dataset'] == dskey]\n",
    "\n",
    "            n_labels = len(datasets[dskey]['target'])\n",
    "            \n",
    "            n_bins = 34 if dskey == 'vitis_types' else 16\n",
    "\n",
    "            for ax, p, tname, color in zip(axes[row].ravel(), to_plot, treatments, colors):\n",
    "                ax.hist(np.array(p['permutations'])*100, range=(0, 100.01), label=name + ' Permutations',\n",
    "                        bins=n_bins, edgecolor='black', color=color)\n",
    "                #ax.axvline(p['non_permuted_CV']*100)\n",
    "\n",
    "                ax.plot(2 * [p['non_permuted_CV'] * 100], ylim, '-', linewidth=3, color=color, #alpha = 0.5,\n",
    "                         label=name + ' (pvalue %.5f)' % p['p-value'], solid_capstyle='round')\n",
    "                #q.set(xlabel='Cross Validation Prediction Accuracy (%)', ylabel='Nº of occurrences', fontsize=12)\n",
    "                #ax.set_xlabel('CV Prediction Accuracy (%)')\n",
    "                #ax.set_ylabel('Nº of occurrences')\n",
    "                props = dict(boxstyle='round', facecolor='white', alpha=1)\n",
    "                ax.text(90, 190, 'p-value = %.3f' % p['p-value'], bbox=props, ha='right', fontsize='small')\n",
    "                ax.set_title(f\"{datasets[dskey]['name']}, {tname}\", color=color)\n",
    "                ax.set_ylim(0,250)\n",
    "\n",
    "        f.text(0.5, 0.01, 'CV Prediction Accuracy (%)', ha='center', va='top')\n",
    "        #f.text(0, 0.5, 'Counts', ha='center', va='top',rotation=90)\n",
    "        \n",
    "        \n",
    "        f.suptitle(f'Permutation tests for PLS-DA')\n",
    "        plt.tight_layout()\n",
    "        f.savefig('paperimages/permutations_PLSDA.pdf', dpi=200)\n",
    "        f.savefig('paperimages/permutations_PLSDA.png', dpi=600)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
